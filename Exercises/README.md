# Additional Resources

## Lab session 1
- [Python Documentation](https://docs.python.org/3/contents.html)
    - [PEP 8 â€“ Style Guide for Python Code](https://peps.python.org/pep-0008/)
- [git - the simple guide](https://rogerdudler.github.io/git-guide/)
- [Conda User guide](https://docs.conda.io/projects/conda/en/latest/user-guide/index.html/)
- [Markdown Basic Syntax](https://www.markdownguide.org/basic-syntax/)

## Lab session 2
- [What is machine learning?](https://www.ibm.com/think/topics/machine-learning)
    - [Supervised Machine Learning: Regression and Classification](https://www.coursera.org/learn/machine-learning)
- [What is a neural network?](https://www.ibm.com/think/topics/neural-networks)
    - [Dive into Deep Learning](https://www.d2l.ai/index.html)
    - [Multilayer perceptron](https://www.d2l.ai/chapter_multilayer-perceptrons/index.html)
    - [Building makemore](https://www.youtube.com/watch?v=TCH_1BHY58I)

## Lab session 3
- [What are word embeddings?](https://www.ibm.com/think/topics/word-embeddings)
    - [Word Embeddings: Encoding Lexical Semantics](https://docs.pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html)
    - [Word Embeddings, NLP Course|For you](https://lena-voita.github.io/nlp_course/word_embeddings.html)
    - [Understanding and Creating Word Embeddings](https://docs.google.com/document/d/1PVlJTrdDe_HO1BdPISdagsM3vwJtLNHJr0HWcWO2xvc/edit#heading=h.qxhue3igmy2l)
- [Perplexity](https://en.wikipedia.org/wiki/Perplexity)
    - [Perplexity for LLM Evaluation](https://www.comet.com/site/blog/perplexity-for-llm-evaluation/)
    - [Perplexity explained with simple probabilities](https://medium.com/nlplanet/two-minutes-nlp-perplexity-explained-with-simple-probabilities-6cdc46884584)
